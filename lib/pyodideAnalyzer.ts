import { PyodideInterface } from './usePyodide'
import { generateExcelFile } from './excelGenerator'
import { AnalysisResult } from './types'

export async function analyzeWithPyodide(
  pyodide: PyodideInterface,
  dataFile: File
): Promise<AnalysisResult> {
  try {
    console.log('üìä D√©but de l\'analyse avec Pyodide...')

    // Charger le fichier unique dans le syst√®me de fichiers virtuel de Pyodide
    const dataBuffer = await dataFile.arrayBuffer()
    pyodide.FS.writeFile('data.xlsx', new Uint8Array(dataBuffer))

    console.log('‚úÖ Fichier charg√© dans Pyodide')

    // Le code Python d'analyse (copi√© depuis analyze.py)
    const pythonCode = `
import pandas as pd
import json
import re
import unicodedata

# Cat√©gories d'examens
CATEGORIES = {
    'IRM': ['irm', 'imagerie par r√©sonance magn√©tique'],
    'SCANNER': ['scanner', 'tdm', 'tomodensitom√©trie', 'ct', 'coroscanner', 'angioscanner'],
    'RADIOGRAPHIE': ['radio', 'radiographie', 'rx', 't√©l√©radiographie'],
    'MAMMOGRAPHIE': ['mammographie', 'mammo'],
    'ECHOGRAPHIE': ['√©chographie', 'echographie', '√©cho', 'echo', 'doppler'],
    'CONE BEAM': ['cone beam', 'conebeam'],
    'DENTAIRE': ['dentaire', 'panoramique dentaire', 'orthopantomogramme']
}

# Liste consolid√©e de tous les termes m√©dicaux/anatomiques valides
# Extraits depuis reference_exams.csv - Un intitul√© est VALIDE s'il contient AU MOINS UN de ces termes
TERMES_MEDICAUX_VALIDES = [
    # Types d'examens
    'irm', 'scanner', 'tdm', 'cone beam', 'conebeam', 'radio', 'radiographie', 'echographie', '√©chographie',
    'doppler', 'mammographie', 'mammo', 'eos', 'ost√©odensitom√©trie', 'densitom√©trie',
    'arthroscanner', 'angioscanner', 'coroscanner', 'dentascanner',

    # Termes anatomiques et m√©dicaux extraits de reference_exams.csv
    'abdo', 'abdo-pelvienne', 'abdomen', 'abdominal', 'abdominale', 'abdomino', 'abdomino-pelvien',
    'abdomino-pelvienne', 'abdomino-r√©nale', 'achille', 'acide', 'acromiale', 'acromio',
    'acromio-claviculaire', 'adducteurs', 'aisselle', 'anal', 'angio-irm', 'anus', 'aorte', 'aortique',
    'art√©riel', 'art√©rielle', 'art√©rioveineux', 'art√®res', 'arthrographie', 'articulaire', 'articulation',
    'articulations', 'atm', 'auditifs', 'avant-bras', 'axillaire', 'bassin', 'biceps', 'biliaire',
    'biliaires', 'biopsie', 'brachial', 'bras', 'b√©b√©', 'cai', 'calcaneum', 'calcan√©ums', 'calcique',
    'canal', 'cancer', 'cardiaque', 'cardiologie', 'carotide', 'carotides', 'cavum', 'cervical',
    'cervicale', 'cervicales', 'cervico', 'cervico-dorsal', 'cervico-dorso-lombaire',
    'cervico-enc√©phalique', 'cervico-lombaire', 'cervico-thoracique', 'cheville', 'chevilles',
    'chirurgie', 'cholangiographie', 'cholesteatome', 'cimentoplastie', 'claviculaire', 'clavicule',
    'coccygienne', 'coccyx', 'cochl√©aire', 'coeur', 'col', 'colon', 'colonne', 'coloscanner',
    'coloscopie', 'conduits', 'coronaires', 'costal', 'costale', 'cou', 'coude', 'coudes', 'creux',
    'croissance', 'cryoth√©rapie', 'cr√¢ne', 'cr√¢nienne', 'cubitus', 'cuisse', 'cystographie',
    'cytoponction', 'c√©r√©bral', 'c√©r√©brale', 'c√¥tes', 'dacryoscanner', 'datation', 'densitom√©trie',
    'dentaire', 'dentaires', 'dents', 'diffusion', 'disque', 'doigt', 'dorsal', 'dorsale', 'dorsaux',
    'dorso', 'dorso-lombaire', 'dorsolombaire', 'dos', 'duod√©nal', 'dynamique', 'd√©f√©co-irm',
    'd√©f√©cographie', 'd√©pistage', 'ecg', 'echocardiographie', 'effort', 'electrocardiogramme',
    'electromyogramme', 'enc√©phale', 'enc√©phalique', 'endom√©triose', 'endom√©trioses', 'endovaginale',
    'entero', 'entero-irm', 'entier', 'ent√©ro-scanner', 'epaule', 'estomac', 'face', 'facial',
    'faciale', 'femme', 'ferrique', 'fesse', 'fessier', 'fessiers', 'fessi√®re', 'fibroscan',
    'fistule', 'fistulographie', 'foie', 'fontanelles', 'foraminale', 'fosse', 'fossettes', 'frontale',
    'fullspine', 'f√©minin', 'f√©mur', 'galactographie', 'ganglion', 'gastro', 'gastrographine',
    'genou', 'genoux', 'glande', 'glandes', 'glut√©ale', 'goniom√©trie', 'gonom√©trie', 'gorge', 'greffon',
    'gril', 'grill', 'gros', 'grossesse', 'gr√™le', 'g√©mellaire', 'hanche', 'hanches', 'hemochromatose',
    'holorachis', 'homme', 'huber', 'humerus', 'hum√©rus', 'hyaluronique', 'hydrosolubles', 'hypophysaire',
    'hypophyse', 'hysterosonographie', 'hyst√©rographie', 'hyst√©rosalpingographie', 'h√©mi-squelette',
    'h√©patique', 'h√©patobiliaire', 'iliaque', 'iliaques', 'implant', 'implantation', 'implants',
    'impulsionnelle', 'infertilit√©', 'infiltration', 'inf√©rieur', 'inf√©rieurs', 'inguinal', 'inguinale',
    'injection', 'internes', 'intestin', 'intra', 'intra-articulaire', 'intraveineuse', 'irmpelvien',
    'ischio', 'ischio-jambiers', 'isocin√©tisme', 'ivg', 'jambe', 'joue', 'kin√©', 'kyste', 'l4', 'l5',
    'lacrymales', 'laser', 'lavement', 'ligamentaire', 'lipome', 'lombaire', 'lombaires', 'l√®vre',
    'machoire', 'macrobiopsie', 'main', 'mains', 'mamelon', 'mammaire', 'mandibulaire', 'mandibulaires',
    'mapa', 'masculin', 'massif', 'maxillaire', 'membre', 'membres', 'menton', 'mesure', 'moelle',
    'molles', 'mollet', 'monitorage', 'morphologique', 'mou', 'mous', 'moyen', 'moyenne', 'muscle',
    'muscles', 'musculaire', 'myocardique', 'm√©diastinale', 'm√©dullaire', 'nerfs', 'nez', 'nuque',
    'obst√©trique', 'occipitale', 'oculaire', 'oesogastroduod√©nal', 'oil', 'omoplate', 'ongles',
    'ophtalmologie', 'opn', 'orbites', 'oreille', 'orl', 'orteil', 'orteils', 'orthodontique',
    'orthopantomogramme', 'os', 'osophagien', 'osseuse', 'osseux', 'osth√©opathie', 'ost√©o-articulaire',
    'ovaires', 'ovarienne', 'ovulation', 'oxyg√©noth√©rapie', 'pancr√©as', 'pancr√©atique', 'pangonogramme',
    'pangonom√©trie', 'panoramique', 'param√®tres', 'parathyro√Øde', 'pari√©tale', 'paroi', 'parotide',
    'parotidienne', 'parties', 'peau', 'pelvi', 'pelvien', 'pelvienne', 'pelvim√©trie', 'pelvis',
    'penis', 'pharyngo', 'pharyngographie', 'pharyng√©', 'pharynx', 'pied', 'pieds', 'plaquettes',
    'plasma', 'plexus', 'pneumo', 'pneumothorax', 'podologique', 'podom√©trie', 'poignet', 'poignets',
    'poitrine', 'ponction', 'postural', 'post√©rieure', 'pouce', 'poumons', 'pression', 'profil',
    'propres', 'prostate', 'prostatique', 'prp', 'pr√©l√©vement', 'pr√©paration', 'pubienne', 'pulmonaire',
    'pylore', 'p√©diatrique', 'p√©nis', 'p√©rin√©ale', 'p√©ron√©', 'rachidiens', 'rachis', 'radiculographie',
    'rate', 'rectum', 'rein', 'reins', 'releveur', 'renal', 'rhino', 'rhumatologique', 'riche',
    'rochers', 'r√©gion', 'r√©nal', 'r√©nale', 'r√©nales', 'r√©no', 'r√©trograde', 'r√©√©ducation',
    'saccoradiculographie', 'sacro', 'sacro-coccygienens', 'sacrum', 'sacr√©', 'salivaires', 'scoliose',
    'score', 'scrotal', 'scrotale', 'scrotum', 'sein', 'seins', 'semaines', 'sialographie', 'sinus',
    'sinusien', 'sous-maxillaire', 'spirom√©trie', 'squelette', 'statique', 'sternum', 'stress',
    'st√©rilet', 'st√©r√©otaxique', 'supra', 'supra-aortiques', 'supro', 'sup√©rieur', 'sup√©rieurs',
    'surcharge', 'surrenales', 'surrenalien', 'surr√©nales', 'sus', 'syst√®me', 's√©nologique',
    's√©samo√Ødes', 'talon', 'tap', 'tavi', 'tel√©cr√¢ne', 'temporal', 'temporo', 'temporo-mandibulaire',
    'temporo-mandibulaires', 'tendineux', 'tendinopathie', 'tendon', 'test', 'testiculaire', 'testicules',
    'thoracique', 'thoraco', 'thoraco-abdominal', 'thoraco-abdomino-pelvien', 'thoraco-pelvienne',
    'thorax', 'thyro√Øde', 'thyro√Ødien', 'thyro√Ødienne', 'tibia', 'tissu', 'tissus', 'togd', 'totale',
    'totalit√©', 'tractions', 'trans', 'transcatheter', 'transcr√¢nien', 'transfontanellaire', 'transit',
    'trap√®ze', 'triceps', 'trimestre', 'trituration', 'trochanter', 'trompes', 'tronc', 'troncs', 'tsa',
    'tum√©faction', 't√©l√©', 't√©l√©crane', 't√©l√©cr√¢ne', 't√©l√©rachis', 't√©l√©radiographie', 't√™te', 'uiv',
    'urinaire', 'urinaires', 'urographie', 'uroscanner', 'ut√©rus', 'vaisseaux', 'valgus', 'valve',
    'varus', 'vdmi', 'veineux', 'ventre', 'verge', 'vert√©bral', 'vert√©brale', 'vesico', 'vessie',
    'virtuelle', 'visage', 'voies', 'v√©g√©tations', 'v√©sicale', 'v√©siculaire', 'v√©sicule', 'yeux',
    '√¢ge', '√©lastographie', '√©lastom√©trie', '√©paule', '√©paules', '√©pidurale', '√©preuve', '√©tude',
]

def is_valid_exam(exam_text):
    """
    V√©rifie si l'intitul√© est un examen valide.

    REGLE SIMPLE : Un intitul√© est VALIDE s'il contient AU MOINS UN terme m√©dical/anatomique
    de la liste TERMES_MEDICAUX_VALIDES.

    Sinon ‚Üí INTITULES INCOHERENTS
    """
    if pd.isna(exam_text) or not str(exam_text).strip():
        return False

    exam_lower = str(exam_text).lower().strip()

    # V√©rifier si l'intitul√© contient au moins un terme m√©dical valide
    for terme in TERMES_MEDICAUX_VALIDES:
        if terme in exam_lower:
            return True

    return False

def categorize_exam(exam_text, apply_filter=True):
    """Cat√©gorise un examen"""
    if pd.isna(exam_text) or not str(exam_text).strip():
        return 'INCONNU'

    exam_lower = str(exam_text).lower().strip()

    # Si l'examen n'est pas valide (type d'examen sans terme anatomique, ou rien de m√©dical)
    # Seulement pour les probl√®mes (not_found, not_authorized), pas pour les rendez-vous cr√©√©s
    if apply_filter and not is_valid_exam(exam_text):
        return 'INTITULES INCOHERENTS'

    # D√©terminer la cat√©gorie
    for category, keywords in CATEGORIES.items():
        for keyword in keywords:
            if keyword in exam_lower:
                return category

    return 'AUTRE'

def parse_exam_identified(exam_str):
    """Parse la colonne 'Examen Identifi√©'"""
    if pd.isna(exam_str):
        return []
    return [e.strip() for e in str(exam_str).split(';') if e.strip()]

def clean_exam_name(exam_str):
    """Nettoie un nom d'examen pour l'affichage : supprime la ponctuation"""
    if pd.isna(exam_str):
        return ''

    # Supprimer la ponctuation (virgules, points, points-virgules)
    cleaned = str(exam_str).replace(',', '').replace('.', '').replace(';', '')

    return cleaned.strip()

def is_exam_too_vague(exam_str):
    """V√©rifie si un intitul√© d'examen est trop vague (un seul mot significatif)"""
    if pd.isna(exam_str) or not str(exam_str).strip():
        return True

    text = str(exam_str).lower().strip()

    # Supprimer la ponctuation
    text = text.replace(',', ' ').replace('.', ' ').replace(';', ' ')

    # Phrases √† retirer compl√®tement (ordre important: plus longues d'abord)
    phrases_to_remove = [
        'prendre un rendez-vous',
        'prendre rendez-vous',
        'un rendez-vous de',
        'un rendez-vous pour',
        'rendez-vous pour',
        'rendez-vous de',
        'rendez-vous',
        'rdv pour',
        'rdv de',
        'rdv',
    ]

    for phrase in phrases_to_remove:
        text = text.replace(phrase, ' ')

    # Mots non significatifs √† retirer
    stop_words = ['un', 'une', 'le', 'la', 'les', "l'", 'de', 'du', 'des', 'pour', 'avec', 'et', 'au', 'aux', 'en', 'sur', 'a', '√†']

    # S√©parer en mots et filtrer
    words = text.split()
    significant_words = [w for w in words if w not in stop_words and len(w) > 1]

    # Si un seul mot significatif ou moins, c'est trop vague
    return len(significant_words) <= 1

def normalize_exam_name(exam_str):
    """Normalise un nom d'examen : minuscules + sans accents + sans ponctuation"""
    if pd.isna(exam_str):
        return ''

    # Convertir en minuscules
    normalized = str(exam_str).lower()

    # Supprimer les accents avec unicodedata (m√©thode standard)
    nfd = unicodedata.normalize('NFD', normalized)
    without_accents = ''.join(char for char in nfd if unicodedata.category(char) != 'Mn')

    # Supprimer la ponctuation (virgules, points, points-virgules)
    without_punctuation = without_accents.replace(',', '').replace('.', '').replace(';', '')

    return without_punctuation.strip()

# Charger le fichier unique
print("üìä Chargement des donn√©es depuis le fichier unique...")
import os

# Cr√©er des DataFrames vides avec les colonnes n√©cessaires
empty_columns = ['Id', 'Id Externe', 'Statut', 'Tag', 'Examen Identifi√©', 'Dur√©e']

# Liste de tous les tags √† traiter pour les probl√®mes
PROBLEM_TAGS = [
    'exam_not_found',
    'exam_not_authorized',
    'availabilies_provided',
    'exam_found',
    'multiple_appointments_cancelled',
    'no_availabilities_found'
]

# Charger le fichier data.xlsx
if os.path.exists('data.xlsx'):
    df_all_data = pd.read_excel('data.xlsx')
    print(f"‚úÖ Fichier charg√©: {len(df_all_data)} lignes au total")

    # Cr√©er un dictionnaire pour stocker les DataFrames par tag
    dfs_by_tag = {}

    # Filtrer par Tag pour cr√©er les DataFrames
    # Pour tous les tags de probl√®mes: on filtre aussi par Statut (Transf√©r√© ou D√©croch√©)
    for tag in PROBLEM_TAGS:
        dfs_by_tag[tag] = df_all_data[
            (df_all_data['Tag'] == tag) &
            (df_all_data['Statut'].isin(['Transf√©r√©', 'D√©croch√©']))
        ].copy()

    # Pour appointment_created: on prend TOUTES les lignes (pas de filtre Statut)
    df_appointment_created = df_all_data[
        df_all_data['Tag'] == 'appointment_created'
    ].copy()

else:
    print("‚ö†Ô∏è Fichier data.xlsx absent - cr√©ation de DataFrames vides")
    dfs_by_tag = {tag: pd.DataFrame(columns=empty_columns) for tag in PROBLEM_TAGS}
    df_appointment_created = pd.DataFrame(columns=empty_columns)

# Afficher les compteurs
for tag in PROBLEM_TAGS:
    print(f"{tag} (Transf√©r√© + D√©croch√©): {len(dfs_by_tag[tag])} appels")
print(f"Appointment Created (TOUTES les lignes): {len(df_appointment_created)} appels")

# V√©rifier si la colonne Dur√©e existe et la convertir en nombre
for tag in PROBLEM_TAGS:
    dfs_by_tag[tag]['Dur√©e'] = 0

if 'Dur√©e' in df_appointment_created.columns:
    df_appointment_created['Dur√©e'] = pd.to_numeric(df_appointment_created['Dur√©e'], errors='coerce').fillna(0)
else:
    df_appointment_created['Dur√©e'] = 0

# Cr√©er un dictionnaire de mapping Id -> Dur√©e depuis TOUTES les lignes de appointment_created
duration_map = {}
for idx, row in df_appointment_created.iterrows():
    call_id = str(row.get('Id', ''))
    if call_id:
        duration_map[call_id] = row.get('Dur√©e', 0)

print(f"Dur√©es extraites pour {len(duration_map)} appels uniques")

print("üîç Analyse des examens...")

# Cr√©er des dictionnaires pour stocker les r√©sultats d√©taill√©s par tag
detailed_results_by_tag = {tag: [] for tag in PROBLEM_TAGS}
detailed_results_appointments = []

# Analyser chaque tag de probl√®me s√©par√©ment
for tag in PROBLEM_TAGS:
    df_tag = dfs_by_tag[tag]
    for idx, row in df_tag.iterrows():
        # R√©cup√©rer la dur√©e depuis duration_map bas√© sur l'Id de l'appel
        call_id = str(row.get('Id', ''))
        duration = duration_map.get(call_id, 0)

        # Prendre le premier examen pour d√©terminer la cat√©gorie de l'appel
        exams = parse_exam_identified(row['Examen Identifi√©'])
        first_exam = exams[0] if exams else ''
        category = categorize_exam(first_exam)

        detailed_results_by_tag[tag].append({
            'Examen Identifi√©': first_exam,
            'Examen Normalis√©': normalize_exam_name(first_exam),
            'Cat√©gorie': category,
            'Tag': tag,
            'Id Appel': row['Id'],
            'Id Externe': row['Id Externe'],
            'Dur√©e': duration
        })

# Analyser les rendez-vous cr√©√©s (appointment_created)
for idx, row in df_appointment_created.iterrows():
    call_id = str(row.get('Id', ''))
    duration = row.get('Dur√©e', 0)

    exams = parse_exam_identified(row['Examen Identifi√©'])
    first_exam = exams[0] if exams else ''
    category = categorize_exam(first_exam, apply_filter=False)

    detailed_results_appointments.append({
        'Examen Identifi√©': first_exam,
        'Examen Normalis√©': normalize_exam_name(first_exam),
        'Cat√©gorie': category,
        'Tag': 'appointment_created',
        'Id Appel': row['Id'],
        'Id Externe': row['Id Externe'],
        'Dur√©e': duration
    })

# Cr√©er les DataFrames d√©taill√©s par tag
df_detailed_by_tag = {}
for tag in PROBLEM_TAGS:
    if detailed_results_by_tag[tag]:
        df_detailed_by_tag[tag] = pd.DataFrame(detailed_results_by_tag[tag])
    else:
        df_detailed_by_tag[tag] = pd.DataFrame(columns=['Examen Identifi√©', 'Examen Normalis√©', 'Cat√©gorie', 'Tag', 'Id Appel', 'Id Externe', 'Dur√©e'])

df_detailed_appointments = pd.DataFrame(detailed_results_appointments)

if df_detailed_appointments.empty:
    df_detailed_appointments = pd.DataFrame(columns=['Examen Identifi√©', 'Examen Normalis√©', 'Cat√©gorie', 'Tag', 'Id Appel', 'Id Externe', 'Dur√©e'])

print("üìà G√©n√©ration des statistiques...")

# Fonction pour g√©n√©rer des statistiques pour un tag donn√©
def generate_stats_for_tag(df_detailed, tag_name):
    stats = []
    valid_categories = list(CATEGORIES.keys()) + ['INTITULES INCOHERENTS', 'AUTRE', 'INCONNU']

    for category in valid_categories:
        df_cat = df_detailed[df_detailed['Cat√©gorie'] == category]

        total = len(df_cat)
        if total == 0:
            continue

        total_duration = int(df_cat['Dur√©e'].sum())

        # Regrouper les examens par nom normalis√©
        exams_list = []

        for normalized_name, df_exam_group in df_cat.groupby('Examen Normalis√©'):
            if not normalized_name:
                continue

            original_name = clean_exam_name(df_exam_group['Examen Identifi√©'].mode()[0])

            if is_exam_too_vague(original_name):
                continue

            count = len(df_exam_group)
            exam_duration = int(df_exam_group['Dur√©e'].sum())
            ids = df_exam_group['Id Externe'].dropna().astype(str).tolist()

            exams_list.append({
                'name': original_name,
                'total': int(count),
                'not_found': 0,
                'not_authorized': 0,
                'ids': ids,
                'duration': exam_duration
            })

        exams_list.sort(key=lambda x: x['total'], reverse=True)

        stats.append({
            'category': category,
            'total': int(total),
            'exam_not_found': 0,
            'exam_not_authorized': 0,
            'total_duration': total_duration,
            'all_exams': '',
            'exams': exams_list
        })

    return stats

# G√©n√©rer les statistiques s√©par√©es pour chaque tag de probl√®me
stats_by_tag = {}
for tag in PROBLEM_TAGS:
    stats_by_tag[tag] = generate_stats_for_tag(df_detailed_by_tag[tag], tag)

# G√©n√©rer les statistiques pour LES RENDEZ-VOUS CR√â√âS (appointment_created)
appointments_stats = []
valid_categories_appt = list(CATEGORIES.keys()) + ['AUTRE', 'INCONNU']

for category in valid_categories_appt:
    df_cat = df_detailed_appointments[df_detailed_appointments['Cat√©gorie'] == category]

    total = len(df_cat)
    if total == 0:
        continue

    total_duration = int(df_cat['Dur√©e'].sum())
    average_duration = int(df_cat['Dur√©e'].mean()) if total > 0 else 0

    exams_list = []

    for normalized_name, df_exam_group in df_cat.groupby('Examen Normalis√©'):
        if not normalized_name:
            continue

        original_name = clean_exam_name(df_exam_group['Examen Identifi√©'].mode()[0])
        count = len(df_exam_group)
        exam_duration = int(df_exam_group['Dur√©e'].sum())
        exam_avg_duration = int(df_exam_group['Dur√©e'].mean()) if count > 0 else 0
        ids = df_exam_group['Id Externe'].dropna().astype(str).tolist()

        exams_list.append({
            'name': original_name,
            'total': int(count),
            'not_found': 0,
            'not_authorized': 0,
            'ids': ids,
            'duration': exam_duration,
            'average_duration': exam_avg_duration
        })

    exams_list.sort(key=lambda x: x['total'], reverse=True)

    appointments_stats.append({
        'category': category,
        'total': int(total),
        'exam_not_found': 0,
        'exam_not_authorized': 0,
        'total_duration': total_duration,
        'average_duration': average_duration,
        'all_exams': '',
        'exams': exams_list
    })

# Calculer le r√©sum√©
total_calls = sum(len(dfs_by_tag[tag]) for tag in PROBLEM_TAGS)
unique_exams = sum(len(stat['exams']) for stats in stats_by_tag.values() for stat in stats if stat['category'] != 'INTITULES INCOHERENTS')
bugs_detected = sum(len(df_detailed_by_tag[tag][df_detailed_by_tag[tag]['Cat√©gorie'] == 'INTITULES INCOHERENTS']) for tag in PROBLEM_TAGS)
total_duration = int(df_appointment_created['Dur√©e'].sum())
appointments_created = len(df_appointment_created)

summary = {
    'total_calls': int(total_calls),
    'unique_exams': int(unique_exams),
    'categories_found': sum(len(stats) for stats in stats_by_tag.values()),
    'bugs_detected': int(bugs_detected),
    'total_duration': total_duration,
    'appointments_created': int(appointments_created),
    'exam_not_found_count': int(len(dfs_by_tag['exam_not_found'])),
    'exam_not_authorized_count': int(len(dfs_by_tag['exam_not_authorized'])),
    'availabilies_provided_count': int(len(dfs_by_tag['availabilies_provided'])),
    'exam_found_count': int(len(dfs_by_tag['exam_found'])),
    'multiple_appointments_cancelled_count': int(len(dfs_by_tag['multiple_appointments_cancelled'])),
    'no_availabilities_found_count': int(len(dfs_by_tag['no_availabilities_found']))
}

print("‚úÖ Analyse termin√©e !")

# R√©sultat JSON avec statistiques s√©par√©es par tag
result = {
    'summary': summary,
    'exam_not_found_statistics': stats_by_tag['exam_not_found'],
    'exam_not_authorized_statistics': stats_by_tag['exam_not_authorized'],
    'availabilies_provided_statistics': stats_by_tag['availabilies_provided'],
    'exam_found_statistics': stats_by_tag['exam_found'],
    'multiple_appointments_cancelled_statistics': stats_by_tag['multiple_appointments_cancelled'],
    'no_availabilities_found_statistics': stats_by_tag['no_availabilities_found'],
    'appointments_statistics': appointments_stats
}

json.dumps(result)
`

    console.log('üêç Ex√©cution du code Python...')
    const resultJson = await pyodide.runPythonAsync(pythonCode)
    const result = JSON.parse(resultJson)

    console.log('üìä G√©n√©ration du fichier Excel avec JavaScript...')
    const excelBase64 = generateExcelFile(result, result.summary)

    const finalResult: AnalysisResult = {
      ...result,
      excel_file_base64: excelBase64
    }

    console.log('‚úÖ Analyse termin√©e !', finalResult.summary)

    return finalResult
  } catch (error) {
    console.error('‚ùå Erreur lors de l\'analyse:', error)
    throw error
  }
}
