import { PyodideInterface } from './usePyodide'
import { generateExcelFile } from './excelGenerator'
import { AnalysisResult } from './types'

export async function analyzeWithPyodide(
  pyodide: PyodideInterface,
  notFoundFile?: File,
  notAuthorizedFile?: File,
  appointmentCreatedFile?: File
): Promise<AnalysisResult> {
  try {
    console.log('üìä D√©but de l\'analyse avec Pyodide...')

    // Charger les fichiers dans le syst√®me de fichiers virtuel de Pyodide
    if (notFoundFile) {
      const notFoundBuffer = await notFoundFile.arrayBuffer()
      pyodide.FS.writeFile('not_found.xlsx', new Uint8Array(notFoundBuffer))
    }

    if (notAuthorizedFile) {
      const notAuthorizedBuffer = await notAuthorizedFile.arrayBuffer()
      pyodide.FS.writeFile('not_authorized.xlsx', new Uint8Array(notAuthorizedBuffer))
    }

    if (appointmentCreatedFile) {
      const appointmentCreatedBuffer = await appointmentCreatedFile.arrayBuffer()
      pyodide.FS.writeFile('appointment_created.xlsx', new Uint8Array(appointmentCreatedBuffer))
    }

    console.log('‚úÖ Fichiers charg√©s dans Pyodide')

    // Le code Python d'analyse (copi√© depuis analyze.py)
    const pythonCode = `
import pandas as pd
import json
import re
import unicodedata

# Cat√©gories d'examens
CATEGORIES = {
    'IRM': ['irm', 'imagerie par r√©sonance magn√©tique'],
    'SCANNER': ['scanner', 'tdm', 'tomodensitom√©trie', 'ct', 'coroscanner', 'angioscanner'],
    'RADIOGRAPHIE': ['radio', 'radiographie', 'rx', 't√©l√©radiographie'],
    'MAMMOGRAPHIE': ['mammographie', 'mammo'],
    'ECHOGRAPHIE': ['√©chographie', 'echographie', '√©cho', 'echo', 'doppler'],
    'CONE BEAM': ['cone beam', 'conebeam'],
    'DENTAIRE': ['dentaire', 'panoramique dentaire', 'orthopantomogramme']
}

# Types d'examens (modalit√©s)
TYPES_EXAMENS = [
    'irm', 'scanner', 'tdm', 'tomodensitometrie', 'tomodensitom√©trie',
    'radio', 'radiographie', 'rx', 'teleradiographie', 't√©l√©radiographie',
    'echo', '√©cho', 'echographie', '√©chographie', 'doppler',
    'mammographie', 'mammo',
    'cone beam', 'conebeam',
    'panoramique', 'orthopantomogramme',
    'scintigraphie', 'pet', 'tep', 'spect',
    'osteodensitometrie', 'ost√©odensitom√©trie', 'densitometrie', 'densitom√©trie',
    'angiographie', 'arteriographie', 'art√©riographie', 'coroscanner', 'angioscanner',
    'coro', 'coronaro', 'coronarographie',
]

# Termes anatomiques et m√©dicaux valides (hors types d'examens)
TERMES_ANATOMIQUES = [
    # Termes m√©dicaux sp√©cifiques
    'calcique', 'calcification', 'calcium',
    'dentaire', 'dent', 'dents', 'molaire', 'incisive', 'canine',

    # T√™te et cou
    'tete', 't√™te', 'crane', 'cr√¢ne', 'cerveau', 'cerebral', 'c√©r√©bral', 'encephale', 'enc√©phale',
    'sinus', 'facial', 'face', 'machoire', 'm√¢choire', 'mandibule', 'maxillaire',
    'orbite', 'oeil', '≈ìil', 'yeux', 'oreille', 'rocher', 'atm', 'temporo',
    'hypophyse', 'selle turcique', 'cou', 'cervical', 'cervicale', 'larynx', 'thyroide', 'thyro√Øde',
    'parotide', 'glande', 'salivaire',

    # Rachis / Colonne
    'rachis', 'colonne', 'vertebr', 'vert√©br', 'lombaire', 'dorsal', 'thoracique',
    'sacr', 'coccyx', 'sacro', 'iliaque', 'medullaire', 'm√©dullaire', 'moelle',

    # Thorax
    'thorax', 'thoracique', 'poumon', 'pulmonaire', 'plevre', 'pl√®vre', 'pleural',
    'mediastin', 'm√©diastin', 'bronch', 'trachee', 'trach√©e',

    # C≈ìur et vaisseaux
    'coeur', 'c≈ìur', 'cardiaque', 'cardiac', 'coronaire', 'aorte', 'aortique',
    'vasculaire', 'veine', 'veineux', 'artere', 'art√®re', 'arteriel', 'art√©riel',
    'carotide', 'jugulaire', 'angio', 'an√©vrisme', 'anevrisme',

    # Abdomen
    'abdomen', 'abdominal', 'abdomino', 'ventre', 'digestif',
    'foie', 'hepat', 'h√©pat', 'vesicule', 'v√©sicule', 'biliaire', 'voies biliaires',
    'pancreas', 'pancr√©as', 'pancreat', 'pancr√©at',
    'rate', 'splen', 'spl√©n',
    'estomac', 'gastri', 'intestin', 'grele', 'gr√™le', 'colon', 'c√¥lon', 'colique',
    'rectum', 'rectal', 'anus', 'anal', 'appendice',
    'peritoine', 'p√©ritoine', 'retroperitoine', 'r√©trop√©ritoine',

    # Reins et urinaire
    'rein', 'renal', 'r√©nal', 'nephro', 'n√©phro', 'surrenale', 'surr√©nale',
    'urinaire', 'vessie', 'vesical', 'v√©sical', 'uretre', 'ur√®tre', 'uretere', 'uret√®re',
    'uro', 'pyelon', 'py√©lon',

    # Pelvis et g√©nital
    'pelvis', 'pelvien', 'pelvienne', 'bassin',
    'prostate', 'prostatique', 'vesicule seminale', 'v√©sicule s√©minale',
    'testicule', 'testiculaire', 'scrotum', 'scrotal', 'penis', 'p√©nis', 'verge',
    'uterus', 'ut√©rus', 'uterin', 'ut√©rin', 'ovaire', 'ovarien', 'trompe',
    'endometre', 'endom√®tre', 'vagin', 'vaginal', 'vulve', 'perinee', 'p√©rin√©e',

    # Sein
    'sein', 'mammaire', 'mammo',

    # Membres sup√©rieurs
    'epaule', '√©paule', 'scapul', 'clavicule', 'acromio', 'omoplate',
    'bras', 'humer', 'hum√©r', 'coude', 'cubital',
    'avant-bras', 'radius', 'ulna', 'cubitus', 'radial',
    'poignet', 'carpe', 'carpien', 'main', 'doigt', 'phalang', 'metacarp', 'm√©tacarp',

    # Membres inf√©rieurs
    'hanche', 'coxo', 'femoral', 'f√©moral', 'femur', 'f√©mur',
    'cuisse', 'quadriceps', 'ischio',
    'genou', 'rotule', 'patell', 'menisque', 'm√©nisque', 'ligament', 'croise', 'crois√©',
    'jambe', 'tibia', 'tibial', 'perone', 'p√©ron√©', 'fibula', 'fibulaire',
    'cheville', 'malleol', 'mall√©ol', 'talo', 'astragale',
    'pied', 'tarse', 'metatars', 'm√©tatars', 'orteil', 'calcaneum', 'calcan√©um', 'talon',

    # Os et articulations g√©n√©raux
    'os', 'osseux', 'osseuse', 'squelette', 'articul', 'articulaire',
    'tendon', 'ligament', 'muscle', 'musculaire', 'cartilage',
    'synovial', 'bursite', 'enthese', 'enth√®se',

    # Peau et tissus mous
    'peau', 'cutane', 'cutan√©', 'sous-cutan', 'sous-cutan√©', 'dermato',
    'tissu', 'mou', 'graisse', 'adipeux', 'lipome',

    # Termes m√©dicaux g√©n√©raux pertinents
    'biopsie', 'ponction', 'infiltration', 'injection', 'arthro',
    'tumeur', 'tumoral', 'cancer', 'metastase', 'm√©tastase', 'nodule', 'kyste', 'masse',
    'fracture', 'entorse', 'luxation', 'rupture', 'dechirure', 'd√©chirure',
    'hernie', 'discale', 'stenose', 'st√©nose', 'arthrose', 'arthrite',
    'inflammation', 'infection', 'abces', 'abc√®s',
    'corps entier', 'total body', 'body scan',
]

def contains_exam_type(exam_text):
    """V√©rifie si l'intitul√© contient un type d'examen (IRM, Scanner, etc.)"""
    if pd.isna(exam_text) or not str(exam_text).strip():
        return False

    exam_lower = str(exam_text).lower()

    for type_exam in TYPES_EXAMENS:
        if type_exam in exam_lower:
            return True

    return False

def contains_anatomical_term(exam_text):
    """V√©rifie si l'intitul√© contient au moins un terme anatomique"""
    if pd.isna(exam_text) or not str(exam_text).strip():
        return False

    exam_lower = str(exam_text).lower()

    for terme in TERMES_ANATOMIQUES:
        if terme in exam_lower:
            return True

    return False

def is_valid_exam(exam_text):
    """V√©rifie si l'intitul√© est un examen valide"""
    if pd.isna(exam_text) or not str(exam_text).strip():
        return False

    exam_lower = str(exam_text).lower().strip()

    # Mots/patterns qui rendent l'intitul√© invalide (clairement non m√©dicaux)
    invalid_patterns = [
        # Temporel
        'soir', 'matin', 'apres-midi', 'apr√®s-midi', 'demain', 'aujourd',
        'lundi', 'mardi', 'mercredi', 'jeudi', 'vendredi', 'samedi', 'dimanche',
        'janvier', 'fevrier', 'f√©vrier', 'mars', 'avril', 'mai', 'juin',
        'juillet', 'aout', 'ao√ªt', 'septembre', 'octobre', 'novembre', 'decembre', 'd√©cembre',
        # Salutations et phrases non m√©dicales
        'bonjour', 'bonsoir', 'salut', 'merci', 'svp', 'il vous plait',
        # R√©f√©rences personnelles
        'ma mere', 'ma m√®re', 'mon pere', 'mon p√®re', 'ma femme', 'mon mari',
        'mon fils', 'ma fille', 'mon enfant',
        # Autres
        'je veux', 'je voudrais', 'ai besoin', 'aimerais',
    ]

    # Si contient un pattern invalide ‚Üí INCOMPRIS
    for pattern in invalid_patterns:
        if pattern in exam_lower:
            return False

    # Valide si contient au moins un type d'examen OU un terme anatomique
    return contains_exam_type(exam_text) or contains_anatomical_term(exam_text)

def categorize_exam(exam_text, apply_filter=True):
    """Cat√©gorise un examen"""
    if pd.isna(exam_text) or not str(exam_text).strip():
        return 'INCONNU'

    exam_lower = str(exam_text).lower().strip()

    # Si l'examen n'est pas valide (type d'examen sans terme anatomique, ou rien de m√©dical)
    # Seulement pour les probl√®mes (not_found, not_authorized), pas pour les rendez-vous cr√©√©s
    if apply_filter and not is_valid_exam(exam_text):
        return 'INTITULES INCOMPRIS'

    # D√©terminer la cat√©gorie
    for category, keywords in CATEGORIES.items():
        for keyword in keywords:
            if keyword in exam_lower:
                return category

    return 'AUTRE'

def parse_exam_identified(exam_str):
    """Parse la colonne 'Examen Identifi√©'"""
    if pd.isna(exam_str):
        return []
    return [e.strip() for e in str(exam_str).split(';') if e.strip()]

def clean_exam_name(exam_str):
    """Nettoie un nom d'examen pour l'affichage : supprime la ponctuation"""
    if pd.isna(exam_str):
        return ''

    # Supprimer la ponctuation (virgules, points, points-virgules)
    cleaned = str(exam_str).replace(',', '').replace('.', '').replace(';', '')

    return cleaned.strip()

def is_exam_too_vague(exam_str):
    """V√©rifie si un intitul√© d'examen est trop vague (un seul mot significatif)"""
    if pd.isna(exam_str) or not str(exam_str).strip():
        return True

    text = str(exam_str).lower().strip()

    # Supprimer la ponctuation
    text = text.replace(',', ' ').replace('.', ' ').replace(';', ' ')

    # Phrases √† retirer compl√®tement (ordre important: plus longues d'abord)
    phrases_to_remove = [
        'prendre un rendez-vous',
        'prendre rendez-vous',
        'un rendez-vous de',
        'un rendez-vous pour',
        'rendez-vous pour',
        'rendez-vous de',
        'rendez-vous',
        'rdv pour',
        'rdv de',
        'rdv',
    ]

    for phrase in phrases_to_remove:
        text = text.replace(phrase, ' ')

    # Mots non significatifs √† retirer
    stop_words = ['un', 'une', 'le', 'la', 'les', "l'", 'de', 'du', 'des', 'pour', 'avec', 'et', 'au', 'aux', 'en', 'sur', 'a', '√†']

    # S√©parer en mots et filtrer
    words = text.split()
    significant_words = [w for w in words if w not in stop_words and len(w) > 1]

    # Si un seul mot significatif ou moins, c'est trop vague
    return len(significant_words) <= 1

def normalize_exam_name(exam_str):
    """Normalise un nom d'examen : minuscules + sans accents + sans ponctuation"""
    if pd.isna(exam_str):
        return ''

    # Convertir en minuscules
    normalized = str(exam_str).lower()

    # Supprimer les accents avec unicodedata (m√©thode standard)
    nfd = unicodedata.normalize('NFD', normalized)
    without_accents = ''.join(char for char in nfd if unicodedata.category(char) != 'Mn')

    # Supprimer la ponctuation (virgules, points, points-virgules)
    without_punctuation = without_accents.replace(',', '').replace('.', '').replace(';', '')

    return without_punctuation.strip()

# Charger les fichiers
print("üìä Chargement des donn√©es...")
import os

# Cr√©er des DataFrames vides avec les colonnes n√©cessaires
empty_columns = ['Id', 'Id Externe', 'Statut', 'Tag', 'Examen Identifi√©', 'Dur√©e']

# Charger not_found ou cr√©er un DataFrame vide
if os.path.exists('not_found.xlsx'):
    df_not_found = pd.read_excel('not_found.xlsx')
    df_not_found = df_not_found[df_not_found['Statut'].isin(['Transf√©r√©', 'D√©croch√©'])].copy()
else:
    print("‚ö†Ô∏è Fichier not_found.xlsx absent - cr√©ation d'un DataFrame vide")
    df_not_found = pd.DataFrame(columns=empty_columns)

# Charger not_authorized ou cr√©er un DataFrame vide
if os.path.exists('not_authorized.xlsx'):
    df_not_authorized = pd.read_excel('not_authorized.xlsx')
    df_not_authorized = df_not_authorized[df_not_authorized['Statut'].isin(['Transf√©r√©', 'D√©croch√©'])].copy()
else:
    print("‚ö†Ô∏è Fichier not_authorized.xlsx absent - cr√©ation d'un DataFrame vide")
    df_not_authorized = pd.DataFrame(columns=empty_columns)

# Charger appointment_created ou cr√©er un DataFrame vide
if os.path.exists('appointment_created.xlsx'):
    df_appointment_created = pd.read_excel('appointment_created.xlsx')
else:
    print("‚ö†Ô∏è Fichier appointment_created.xlsx absent - cr√©ation d'un DataFrame vide")
    df_appointment_created = pd.DataFrame(columns=empty_columns)

# PAS DE FILTRE pour appointment_created - on prend TOUTES les lignes pour le calcul de dur√©e
print(f"Not Found (Transf√©r√© + D√©croch√©): {len(df_not_found)} appels")
print(f"Not Authorized (Transf√©r√© + D√©croch√©): {len(df_not_authorized)} appels")
print(f"Appointment Created (TOUTES les lignes): {len(df_appointment_created)} appels")

# V√©rifier si la colonne Dur√©e existe et la convertir en nombre
# IMPORTANT: La dur√©e est extraite depuis TOUTES les lignes de appointment_created
for df in [df_not_found, df_not_authorized]:
    df['Dur√©e'] = 0

if 'Dur√©e' in df_appointment_created.columns:
    df_appointment_created['Dur√©e'] = pd.to_numeric(df_appointment_created['Dur√©e'], errors='coerce').fillna(0)
else:
    df_appointment_created['Dur√©e'] = 0

# Cr√©er un dictionnaire de mapping Id -> Dur√©e depuis TOUTES les lignes de appointment_created
duration_map = {}
for idx, row in df_appointment_created.iterrows():
    call_id = str(row.get('Id', ''))
    if call_id:
        duration_map[call_id] = row.get('Dur√©e', 0)

print(f"Dur√©es extraites pour {len(duration_map)} appels uniques")

# Ajouter les tags
df_not_found['tag_type'] = 'exam_not_found'
df_not_authorized['tag_type'] = 'exam_not_authorized'

# Combiner UNIQUEMENT not_found et not_authorized pour l'analyse des examens
df_all = pd.concat([df_not_found, df_not_authorized], ignore_index=True)

print("üîç Analyse des examens...")

# Cr√©er deux listes d√©taill√©es s√©par√©es : une pour les probl√®mes, une pour les succ√®s
detailed_results_problems = []
detailed_results_appointments = []

# Analyser les probl√®mes (not_found et not_authorized)
# On compte les appels, pas les examens individuels
for idx, row in df_all.iterrows():
    # R√©cup√©rer la dur√©e depuis duration_map bas√© sur l'Id de l'appel
    call_id = str(row.get('Id', ''))
    duration = duration_map.get(call_id, 0)

    # Prendre le premier examen pour d√©terminer la cat√©gorie de l'appel
    exams = parse_exam_identified(row['Examen Identifi√©'])
    first_exam = exams[0] if exams else ''
    category = categorize_exam(first_exam)

    detailed_results_problems.append({
        'Examen Identifi√©': first_exam,
        'Examen Normalis√©': normalize_exam_name(first_exam),
        'Cat√©gorie': category,
        'Tag': row['tag_type'],
        'Id Appel': row['Id'],
        'Id Externe': row['Id Externe'],
        'Dur√©e': duration
    })

# Analyser les rendez-vous cr√©√©s (appointment_created)
# On compte les appels, pas les examens individuels
# PAS DE FILTRE pour les rendez-vous cr√©√©s - toutes les lignes sont valides
for idx, row in df_appointment_created.iterrows():
    call_id = str(row.get('Id', ''))
    duration = row.get('Dur√©e', 0)  # Dur√©e directe du fichier appointment_created

    # Prendre le premier examen pour d√©terminer la cat√©gorie de l'appel
    exams = parse_exam_identified(row['Examen Identifi√©'])
    first_exam = exams[0] if exams else ''
    category = categorize_exam(first_exam, apply_filter=False)

    detailed_results_appointments.append({
        'Examen Identifi√©': first_exam,
        'Examen Normalis√©': normalize_exam_name(first_exam),
        'Cat√©gorie': category,
        'Tag': 'appointment_created',
        'Id Appel': row['Id'],
        'Id Externe': row['Id Externe'],
        'Dur√©e': duration
    })

df_detailed_problems = pd.DataFrame(detailed_results_problems)
df_detailed_appointments = pd.DataFrame(detailed_results_appointments)

# S'assurer que les DataFrames ont les colonnes n√©cessaires m√™me s'ils sont vides
if df_detailed_problems.empty:
    df_detailed_problems = pd.DataFrame(columns=['Examen Identifi√©', 'Examen Normalis√©', 'Cat√©gorie', 'Tag', 'Id Appel', 'Id Externe', 'Dur√©e'])

if df_detailed_appointments.empty:
    df_detailed_appointments = pd.DataFrame(columns=['Examen Identifi√©', 'Examen Normalis√©', 'Cat√©gorie', 'Tag', 'Id Appel', 'Id Externe', 'Dur√©e'])

print("üìà G√©n√©ration des statistiques...")

# G√©n√©rer les statistiques pour LES PROBL√àMES (not_found et not_authorized)
problems_stats = []
valid_categories = list(CATEGORIES.keys()) + ['INTITULES INCOMPRIS', 'AUTRE', 'INCONNU']

for category in valid_categories:
    df_cat = df_detailed_problems[df_detailed_problems['Cat√©gorie'] == category]

    total = len(df_cat)
    if total == 0:
        continue

    not_found = len(df_cat[df_cat['Tag'] == 'exam_not_found'])
    not_authorized = len(df_cat[df_cat['Tag'] == 'exam_not_authorized'])
    total_duration = int(df_cat['Dur√©e'].sum())

    # Regrouper les examens par nom normalis√© (ignorer casse et accents)
    exams_list = []
    exams_with_ids = []

    # Grouper par 'Examen Normalis√©'
    for normalized_name, df_exam_group in df_cat.groupby('Examen Normalis√©'):
        if not normalized_name:  # Ignorer les vides
            continue

        # Prendre le nom original le plus fr√©quent (pour l'affichage) et le nettoyer
        original_name = clean_exam_name(df_exam_group['Examen Identifi√©'].mode()[0])

        # Ignorer les intitul√©s trop vagues pour l'affichage
        if is_exam_too_vague(original_name):
            continue

        count = len(df_exam_group)
        nf_count = len(df_exam_group[df_exam_group['Tag'] == 'exam_not_found'])
        na_count = len(df_exam_group[df_exam_group['Tag'] == 'exam_not_authorized'])
        exam_duration = int(df_exam_group['Dur√©e'].sum())

        ids = df_exam_group['Id Externe'].dropna().astype(str).tolist()

        exams_list.append({
            'name': original_name,
            'total': int(count),
            'not_found': int(nf_count),
            'not_authorized': int(na_count),
            'ids': ids,
            'duration': exam_duration
        })

        ids_str = '|'.join(ids)
        exams_with_ids.append(f"{original_name}¬ß{count} (NF:{nf_count}|NA:{na_count})¬ß{ids_str}")

    # Trier par total d√©croissant
    exams_list.sort(key=lambda x: x['total'], reverse=True)
    exams_with_ids.sort(key=lambda x: int(x.split('¬ß')[1].split(' ')[0]), reverse=True)

    all_exams_str = '\\n'.join(exams_with_ids)

    problems_stats.append({
        'category': category,
        'total': int(total),
        'exam_not_found': int(not_found),
        'exam_not_authorized': int(not_authorized),
        'total_duration': total_duration,
        'all_exams': all_exams_str,
        'exams': exams_list
    })

# G√©n√©rer les statistiques pour LES RENDEZ-VOUS CR√â√âS (appointment_created)
appointments_stats = []

for category in valid_categories:
    # Pas de cat√©gorie INTITULES INCOMPRIS pour les rendez-vous cr√©√©s
    if category == 'INTITULES INCOMPRIS':
        continue

    df_cat = df_detailed_appointments[df_detailed_appointments['Cat√©gorie'] == category]

    total = len(df_cat)
    if total == 0:
        continue

    total_duration = int(df_cat['Dur√©e'].sum())
    average_duration = int(df_cat['Dur√©e'].mean()) if total > 0 else 0

    # Regrouper les examens par nom normalis√©
    exams_list = []

    for normalized_name, df_exam_group in df_cat.groupby('Examen Normalis√©'):
        if not normalized_name:
            continue

        original_name = clean_exam_name(df_exam_group['Examen Identifi√©'].mode()[0])
        count = len(df_exam_group)
        exam_duration = int(df_exam_group['Dur√©e'].sum())
        exam_avg_duration = int(df_exam_group['Dur√©e'].mean()) if count > 0 else 0
        ids = df_exam_group['Id Externe'].dropna().astype(str).tolist()

        exams_list.append({
            'name': original_name,
            'total': int(count),
            'not_found': 0,  # Pas de not_found pour les succ√®s
            'not_authorized': 0,  # Pas de not_authorized pour les succ√®s
            'ids': ids,
            'duration': exam_duration,
            'average_duration': exam_avg_duration
        })

    # Trier par total d√©croissant
    exams_list.sort(key=lambda x: x['total'], reverse=True)

    appointments_stats.append({
        'category': category,
        'total': int(total),
        'exam_not_found': 0,
        'exam_not_authorized': 0,
        'total_duration': total_duration,
        'average_duration': average_duration,
        'all_exams': '',
        'exams': exams_list
    })

# Calculer le r√©sum√©
total_calls = len(df_not_found) + len(df_not_authorized)
# Compter les examens affich√©s dans les tableaux (hors INTITULES INCOMPRIS)
unique_exams = sum(len(stat['exams']) for stat in problems_stats if stat['category'] != 'INTITULES INCOMPRIS')
bugs_detected = len(df_detailed_problems[df_detailed_problems['Cat√©gorie'] == 'INTITULES INCOMPRIS'])
# Calculer la dur√©e totale UNIQUEMENT depuis appointment_created
total_duration = int(df_appointment_created['Dur√©e'].sum())
# Calculer le nombre de rendez-vous cr√©√©s (nombre de lignes dans appointment_created)
appointments_created = len(df_appointment_created)

summary = {
    'total_calls': int(total_calls),
    'unique_exams': int(unique_exams),
    'categories_found': len(problems_stats),
    'bugs_detected': int(bugs_detected),
    'total_duration': total_duration,
    'appointments_created': int(appointments_created)
}

print("‚úÖ Analyse termin√©e !")

# R√©sultat JSON (Excel sera g√©n√©r√© c√¥t√© JavaScript)
result = {
    'summary': summary,
    'problems_statistics': problems_stats,
    'appointments_statistics': appointments_stats
}

json.dumps(result)
`

    console.log('üêç Ex√©cution du code Python...')
    const resultJson = await pyodide.runPythonAsync(pythonCode)
    const result = JSON.parse(resultJson)

    console.log('üìä G√©n√©ration du fichier Excel avec JavaScript...')
    const excelBase64 = generateExcelFile(result.problems_statistics, result.appointments_statistics, result.summary)

    const finalResult: AnalysisResult = {
      ...result,
      excel_file_base64: excelBase64
    }

    console.log('‚úÖ Analyse termin√©e !', finalResult.summary)

    return finalResult
  } catch (error) {
    console.error('‚ùå Erreur lors de l\'analyse:', error)
    throw error
  }
}
