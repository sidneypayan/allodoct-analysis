import { PyodideInterface } from './usePyodide'
import { generateExcelFile } from './excelGenerator'
import { AnalysisResult } from './types'

export async function analyzeWithPyodide(
  pyodide: PyodideInterface,
  notFoundFile?: File,
  notAuthorizedFile?: File,
  appointmentCreatedFile?: File
): Promise<AnalysisResult> {
  try {
    console.log('üìä D√©but de l\'analyse avec Pyodide...')

    // Charger les fichiers dans le syst√®me de fichiers virtuel de Pyodide
    if (notFoundFile) {
      const notFoundBuffer = await notFoundFile.arrayBuffer()
      pyodide.FS.writeFile('not_found.xlsx', new Uint8Array(notFoundBuffer))
    }

    if (notAuthorizedFile) {
      const notAuthorizedBuffer = await notAuthorizedFile.arrayBuffer()
      pyodide.FS.writeFile('not_authorized.xlsx', new Uint8Array(notAuthorizedBuffer))
    }

    if (appointmentCreatedFile) {
      const appointmentCreatedBuffer = await appointmentCreatedFile.arrayBuffer()
      pyodide.FS.writeFile('appointment_created.xlsx', new Uint8Array(appointmentCreatedBuffer))
    }

    console.log('‚úÖ Fichiers charg√©s dans Pyodide')

    // Le code Python d'analyse (copi√© depuis analyze.py)
    const pythonCode = `
import pandas as pd
import json
import re
import unicodedata

# Cat√©gories d'examens
CATEGORIES = {
    'IRM': ['irm', 'imagerie par r√©sonance magn√©tique'],
    'SCANNER': ['scanner', 'tdm', 'tomodensitom√©trie', 'ct', 'coroscanner', 'angioscanner'],
    'RADIOGRAPHIE': ['radio', 'radiographie', 'rx', 't√©l√©radiographie'],
    'MAMMOGRAPHIE': ['mammographie', 'mammo'],
    'ECHOGRAPHIE': ['√©chographie', 'echographie', '√©cho', 'echo', 'doppler'],
    'CONE BEAM': ['cone beam', 'conebeam'],
    'DENTAIRE': ['dentaire', 'panoramique dentaire', 'orthopantomogramme']
}

def categorize_exam(exam_text):
    """Cat√©gorise un examen"""
    if pd.isna(exam_text) or not str(exam_text).strip():
        return 'INCONNU'

    exam_lower = str(exam_text).lower().strip()

    # V√©rifier intitul√©s incompris
    incomprehensible_patterns = [
        r'ma m√®re', r'ma femme', r'mon mari', r'mon p√®re',
        r'un.*pour', r'je veux', r'j\\'ai besoin',
        r'\\d+\\s*ans', r'bonjour', r'consultation',
    ]

    for pattern in incomprehensible_patterns:
        if re.search(pattern, exam_lower):
            return 'INTITULES INCOMPRIS'

    # D√©terminer la cat√©gorie
    for category, keywords in CATEGORIES.items():
        for keyword in keywords:
            if keyword in exam_lower:
                return category

    return 'AUTRE'

def parse_exam_identified(exam_str):
    """Parse la colonne 'Examen Identifi√©'"""
    if pd.isna(exam_str):
        return []
    return [e.strip() for e in str(exam_str).split(';') if e.strip()]

def normalize_exam_name(exam_str):
    """Normalise un nom d'examen : minuscules + sans accents"""
    if pd.isna(exam_str):
        return ''

    # Convertir en minuscules
    normalized = str(exam_str).lower()

    # Supprimer les accents avec unicodedata (m√©thode standard)
    nfd = unicodedata.normalize('NFD', normalized)
    without_accents = ''.join(char for char in nfd if unicodedata.category(char) != 'Mn')

    return without_accents.strip()

# Charger les fichiers
print("üìä Chargement des donn√©es...")
import os

# Cr√©er des DataFrames vides avec les colonnes n√©cessaires
empty_columns = ['Id', 'Id Externe', 'Statut', 'Tag', 'Examen Identifi√©', 'Dur√©e']

# Charger not_found ou cr√©er un DataFrame vide
if os.path.exists('not_found.xlsx'):
    df_not_found = pd.read_excel('not_found.xlsx')
    df_not_found = df_not_found[df_not_found['Statut'].isin(['Transf√©r√©', 'D√©croch√©'])].copy()
else:
    print("‚ö†Ô∏è Fichier not_found.xlsx absent - cr√©ation d'un DataFrame vide")
    df_not_found = pd.DataFrame(columns=empty_columns)

# Charger not_authorized ou cr√©er un DataFrame vide
if os.path.exists('not_authorized.xlsx'):
    df_not_authorized = pd.read_excel('not_authorized.xlsx')
    df_not_authorized = df_not_authorized[df_not_authorized['Statut'].isin(['Transf√©r√©', 'D√©croch√©'])].copy()
else:
    print("‚ö†Ô∏è Fichier not_authorized.xlsx absent - cr√©ation d'un DataFrame vide")
    df_not_authorized = pd.DataFrame(columns=empty_columns)

# Charger appointment_created ou cr√©er un DataFrame vide
if os.path.exists('appointment_created.xlsx'):
    df_appointment_created = pd.read_excel('appointment_created.xlsx')
else:
    print("‚ö†Ô∏è Fichier appointment_created.xlsx absent - cr√©ation d'un DataFrame vide")
    df_appointment_created = pd.DataFrame(columns=empty_columns)

# PAS DE FILTRE pour appointment_created - on prend TOUTES les lignes pour le calcul de dur√©e
print(f"Not Found (Transf√©r√© + D√©croch√©): {len(df_not_found)} appels")
print(f"Not Authorized (Transf√©r√© + D√©croch√©): {len(df_not_authorized)} appels")
print(f"Appointment Created (TOUTES les lignes): {len(df_appointment_created)} appels")

# V√©rifier si la colonne Dur√©e existe et la convertir en nombre
# IMPORTANT: La dur√©e est extraite depuis TOUTES les lignes de appointment_created
for df in [df_not_found, df_not_authorized]:
    df['Dur√©e'] = 0

if 'Dur√©e' in df_appointment_created.columns:
    df_appointment_created['Dur√©e'] = pd.to_numeric(df_appointment_created['Dur√©e'], errors='coerce').fillna(0)
else:
    df_appointment_created['Dur√©e'] = 0

# Cr√©er un dictionnaire de mapping Id -> Dur√©e depuis TOUTES les lignes de appointment_created
duration_map = {}
for idx, row in df_appointment_created.iterrows():
    call_id = str(row.get('Id', ''))
    if call_id:
        duration_map[call_id] = row.get('Dur√©e', 0)

print(f"Dur√©es extraites pour {len(duration_map)} appels uniques")

# Ajouter les tags
df_not_found['tag_type'] = 'exam_not_found'
df_not_authorized['tag_type'] = 'exam_not_authorized'

# Combiner UNIQUEMENT not_found et not_authorized pour l'analyse des examens
df_all = pd.concat([df_not_found, df_not_authorized], ignore_index=True)

print("üîç Analyse des examens...")

# Cr√©er deux listes d√©taill√©es s√©par√©es : une pour les probl√®mes, une pour les succ√®s
detailed_results_problems = []
detailed_results_appointments = []

# Analyser les probl√®mes (not_found et not_authorized)
# On compte les appels, pas les examens individuels
for idx, row in df_all.iterrows():
    # R√©cup√©rer la dur√©e depuis duration_map bas√© sur l'Id de l'appel
    call_id = str(row.get('Id', ''))
    duration = duration_map.get(call_id, 0)

    # Prendre le premier examen pour d√©terminer la cat√©gorie de l'appel
    exams = parse_exam_identified(row['Examen Identifi√©'])
    first_exam = exams[0] if exams else ''
    category = categorize_exam(first_exam)

    detailed_results_problems.append({
        'Examen Identifi√©': first_exam,
        'Examen Normalis√©': normalize_exam_name(first_exam),
        'Cat√©gorie': category,
        'Tag': row['tag_type'],
        'Id Appel': row['Id'],
        'Id Externe': row['Id Externe'],
        'Dur√©e': duration
    })

# Analyser les rendez-vous cr√©√©s (appointment_created)
# On compte les appels, pas les examens individuels
for idx, row in df_appointment_created.iterrows():
    call_id = str(row.get('Id', ''))
    duration = row.get('Dur√©e', 0)  # Dur√©e directe du fichier appointment_created

    # Prendre le premier examen pour d√©terminer la cat√©gorie de l'appel
    exams = parse_exam_identified(row['Examen Identifi√©'])
    first_exam = exams[0] if exams else ''
    category = categorize_exam(first_exam)

    detailed_results_appointments.append({
        'Examen Identifi√©': first_exam,
        'Examen Normalis√©': normalize_exam_name(first_exam),
        'Cat√©gorie': category,
        'Tag': 'appointment_created',
        'Id Appel': row['Id'],
        'Id Externe': row['Id Externe'],
        'Dur√©e': duration
    })

df_detailed_problems = pd.DataFrame(detailed_results_problems)
df_detailed_appointments = pd.DataFrame(detailed_results_appointments)

# S'assurer que les DataFrames ont les colonnes n√©cessaires m√™me s'ils sont vides
if df_detailed_problems.empty:
    df_detailed_problems = pd.DataFrame(columns=['Examen Identifi√©', 'Examen Normalis√©', 'Cat√©gorie', 'Tag', 'Id Appel', 'Id Externe', 'Dur√©e'])

if df_detailed_appointments.empty:
    df_detailed_appointments = pd.DataFrame(columns=['Examen Identifi√©', 'Examen Normalis√©', 'Cat√©gorie', 'Tag', 'Id Appel', 'Id Externe', 'Dur√©e'])

print("üìà G√©n√©ration des statistiques...")

# G√©n√©rer les statistiques pour LES PROBL√àMES (not_found et not_authorized)
problems_stats = []
valid_categories = list(CATEGORIES.keys()) + ['INTITULES INCOMPRIS', 'AUTRE', 'INCONNU']

for category in valid_categories:
    df_cat = df_detailed_problems[df_detailed_problems['Cat√©gorie'] == category]

    total = len(df_cat)
    if total == 0:
        continue

    not_found = len(df_cat[df_cat['Tag'] == 'exam_not_found'])
    not_authorized = len(df_cat[df_cat['Tag'] == 'exam_not_authorized'])
    total_duration = int(df_cat['Dur√©e'].sum())

    # Regrouper les examens par nom normalis√© (ignorer casse et accents)
    exams_list = []
    exams_with_ids = []

    # Grouper par 'Examen Normalis√©'
    for normalized_name, df_exam_group in df_cat.groupby('Examen Normalis√©'):
        if not normalized_name:  # Ignorer les vides
            continue

        # Prendre le nom original le plus fr√©quent (pour l'affichage)
        original_name = df_exam_group['Examen Identifi√©'].mode()[0]

        count = len(df_exam_group)
        nf_count = len(df_exam_group[df_exam_group['Tag'] == 'exam_not_found'])
        na_count = len(df_exam_group[df_exam_group['Tag'] == 'exam_not_authorized'])
        exam_duration = int(df_exam_group['Dur√©e'].sum())

        ids = df_exam_group['Id Externe'].dropna().astype(str).tolist()

        exams_list.append({
            'name': original_name,
            'total': int(count),
            'not_found': int(nf_count),
            'not_authorized': int(na_count),
            'ids': ids,
            'duration': exam_duration
        })

        ids_str = '|'.join(ids)
        exams_with_ids.append(f"{original_name}¬ß{count} (NF:{nf_count}|NA:{na_count})¬ß{ids_str}")

    # Trier par total d√©croissant
    exams_list.sort(key=lambda x: x['total'], reverse=True)
    exams_with_ids.sort(key=lambda x: int(x.split('¬ß')[1].split(' ')[0]), reverse=True)

    all_exams_str = '\\n'.join(exams_with_ids)

    problems_stats.append({
        'category': category,
        'total': int(total),
        'exam_not_found': int(not_found),
        'exam_not_authorized': int(not_authorized),
        'total_duration': total_duration,
        'all_exams': all_exams_str,
        'exams': exams_list
    })

# G√©n√©rer les statistiques pour LES RENDEZ-VOUS CR√â√âS (appointment_created)
appointments_stats = []

for category in valid_categories:
    df_cat = df_detailed_appointments[df_detailed_appointments['Cat√©gorie'] == category]

    total = len(df_cat)
    if total == 0:
        continue

    total_duration = int(df_cat['Dur√©e'].sum())
    average_duration = int(df_cat['Dur√©e'].mean()) if total > 0 else 0

    # Regrouper les examens par nom normalis√©
    exams_list = []

    for normalized_name, df_exam_group in df_cat.groupby('Examen Normalis√©'):
        if not normalized_name:
            continue

        original_name = df_exam_group['Examen Identifi√©'].mode()[0]
        count = len(df_exam_group)
        exam_duration = int(df_exam_group['Dur√©e'].sum())
        exam_avg_duration = int(df_exam_group['Dur√©e'].mean()) if count > 0 else 0
        ids = df_exam_group['Id Externe'].dropna().astype(str).tolist()

        exams_list.append({
            'name': original_name,
            'total': int(count),
            'not_found': 0,  # Pas de not_found pour les succ√®s
            'not_authorized': 0,  # Pas de not_authorized pour les succ√®s
            'ids': ids,
            'duration': exam_duration,
            'average_duration': exam_avg_duration
        })

    # Trier par total d√©croissant
    exams_list.sort(key=lambda x: x['total'], reverse=True)

    appointments_stats.append({
        'category': category,
        'total': int(total),
        'exam_not_found': 0,
        'exam_not_authorized': 0,
        'total_duration': total_duration,
        'average_duration': average_duration,
        'all_exams': '',
        'exams': exams_list
    })

# Calculer le r√©sum√©
total_calls = len(df_not_found) + len(df_not_authorized)
unique_exams = len(df_detailed_problems['Examen Normalis√©'].unique())
bugs_detected = len(df_detailed_problems[df_detailed_problems['Cat√©gorie'] == 'INTITULES INCOMPRIS'])
# Calculer la dur√©e totale UNIQUEMENT depuis appointment_created
total_duration = int(df_appointment_created['Dur√©e'].sum())
# Calculer le nombre de rendez-vous cr√©√©s (nombre de lignes dans appointment_created)
appointments_created = len(df_appointment_created)

summary = {
    'total_calls': int(total_calls),
    'unique_exams': int(unique_exams),
    'categories_found': len(problems_stats),
    'bugs_detected': int(bugs_detected),
    'total_duration': total_duration,
    'appointments_created': int(appointments_created)
}

print("‚úÖ Analyse termin√©e !")

# R√©sultat JSON (Excel sera g√©n√©r√© c√¥t√© JavaScript)
result = {
    'summary': summary,
    'problems_statistics': problems_stats,
    'appointments_statistics': appointments_stats
}

json.dumps(result)
`

    console.log('üêç Ex√©cution du code Python...')
    const resultJson = await pyodide.runPythonAsync(pythonCode)
    const result = JSON.parse(resultJson)

    console.log('üìä G√©n√©ration du fichier Excel avec JavaScript...')
    const excelBase64 = generateExcelFile(result.problems_statistics, result.appointments_statistics, result.summary)

    const finalResult: AnalysisResult = {
      ...result,
      excel_file_base64: excelBase64
    }

    console.log('‚úÖ Analyse termin√©e !', finalResult.summary)

    return finalResult
  } catch (error) {
    console.error('‚ùå Erreur lors de l\'analyse:', error)
    throw error
  }
}
